
@inproceedings{chenFastPatternMatching1995,
  title = {Fast Pattern Matching for Entropy Bounded Text},
  booktitle = {Proceedings {{DCC}}'95 {{Data Compression Conference}}},
  author = {Chen, Shenfeng and Reif, John H.},
  year = {1995},
  pages = {282--291},
  publisher = {{IEEE}},
  file = {/Users/tobinsouth_imac/Zotero/storage/V6QHZ4Q9/515518.html}
}

@inproceedings{chenUsingDifficultyPrediction1993,
  title = {Using Difficulty of Prediction to Decrease Computation: {{Fast}} Sort, Priority Queue and Convex Hull on Entropy Bounded Inputs},
  shorttitle = {Using Difficulty of Prediction to Decrease Computation},
  booktitle = {Proceedings of 1993 {{IEEE}} 34th {{Annual Foundations}} of {{Computer Science}}},
  author = {Chen, Shenfeng and Reif, John H.},
  year = {1993},
  pages = {104--112},
  publisher = {{IEEE}},
  file = {/Users/tobinsouth_imac/Zotero/storage/455NF3BM/Chen and Reif - 1993 - Using difficulty of prediction to decrease computa.pdf;/Users/tobinsouth_imac/Zotero/storage/9TTSVMI4/366877.html}
}

@inproceedings{farachEntropyDNAAlgorithms1995,
  title = {On the Entropy of {{DNA}}: {{Algorithms}} and Measurements Based on Memory and Rapid Convergence},
  shorttitle = {On the Entropy of {{DNA}}},
  booktitle = {Proceedings of the Sixth Annual {{ACM}}-{{SIAM}} Symposium on {{Discrete}} Algorithms},
  author = {Farach, Martin and Noordewier, Michiel and Savari, Serap and Shepp, Larry and Wyner, Abraham and Ziv, Jacob},
  year = {1995},
  pages = {48--57},
  file = {/Users/tobinsouth_imac/Zotero/storage/9ZJPIAFM/Farach et al. - 1995 - On the entropy of DNA Algorithms and measurements.pdf}
}

@article{grassbergerEstimatingInformationContent1989,
  title = {Estimating the Information Content of Symbol Sequences and Efficient Codes},
  author = {Grassberger, P.},
  year = {1989},
  month = may,
  volume = {35},
  pages = {669--675},
  issn = {00189448},
  doi = {10.1109/18.30993},
  abstract = {Several variants of an algorithm for estimating Shannon entropies of symbol sequences are presented. They are all related to the Lempel-Ziv algorithm and to recent algorithms for estimating Hausdorff dimensions. The average storage and running times increase as N and N log N , respectively, with the sequence length N . These algorithms proceed basically by constructing efficient codes. They seem to be the optimal algorithms for sequences with strong long-range correlations, e.g., natural languages. An application to written English illustrates their use.},
  file = {/Users/tobinsouth_imac/Zotero/storage/WIPB22SR/Grassberger - 1989 - Estimating the information content of symbol seque.pdf},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {3}
}

@inproceedings{juolaWhatCanWe1997,
  title = {What Can We Do with Small Corpora? {{Document}} Categorization via Cross-Entropy},
  shorttitle = {What Can We Do with Small Corpora?},
  booktitle = {Proceedings of an {{Interdisciplinary Workshop}} on {{Similarity}} and {{Categorization}}, {{Department}} of {{Artificial Intelligence}}, {{University}} of {{Edinburgh}}, {{Edinburgh}}, {{UK}}},
  author = {Juola, Patrick},
  year = {1997},
  file = {/Users/tobinsouth_imac/Zotero/storage/6JC8XNS9/Juola - 1997 - What can we do with small corpora Document catego.eps}
}

@article{kontoyiannisNonparametricEntropyEstimation1998,
  title = {Nonparametric Entropy Estimation for Stationary Processes and Random Fields, with Applications to {{English}} Text},
  author = {Kontoyiannis, I. and Algoet, P.H. and Suhov, Yu.M. and Wyner, A.J.},
  year = {1998},
  month = may,
  volume = {44},
  pages = {1319--1327},
  issn = {00189448},
  doi = {10.1109/18.669425},
  abstract = {We discuss a family of estimators for the entropy rate of a stationary ergodic process and prove their pointwise and mean consistency under a Doeblin-type mixing condition. The estimators are Cesa`ro averages of longest match-lengths, and their consistency follows from a generalized ergodic theorem due to Maker. We provide examples of their performance on English text, and we generalize our results to countable alphabet processes and to random fields.},
  file = {/Users/tobinsouth_imac/Zotero/storage/AXL56Z2I/Kontoyiannis et al. - 1998 - Nonparametric entropy estimation for stationary pr.pdf},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {3}
}

@inproceedings{kontoyiannisPrefixesEntropyRate1994,
  title = {Prefixes and the Entropy Rate for Long-Range Sources},
  booktitle = {{{IEEE International Symposium}} on {{Information Theory}}},
  author = {Kontoyiannis, Ioannis and Suhov, Yurii M.},
  year = {1994},
  pages = {194--194},
  publisher = {{INSTITUTE OF ELECTRICAL ENGINEERS INC (IEEE)}},
  file = {/Users/tobinsouth_imac/Zotero/storage/S6E3UPTE/Kontoyiannis and Suhov - 1994 - Prefixes and the entropy rate for long-range sourc.pdf}
}

@article{quasEntropyEstimatorClass1999,
  title = {An Entropy Estimator for a Class of Infinite Alphabet Processes},
  author = {Quas, Anthony N.},
  year = {1999},
  volume = {43},
  pages = {496--507},
  file = {/Users/tobinsouth_imac/Zotero/storage/74SLQ4AK/Quas - 1999 - An entropy estimator for a class of infinite alpha.pdf},
  journal = {Theory of Probability \& Its Applications},
  number = {3}
}

@article{shieldsEntropyPrefixes1992,
  title = {Entropy and Prefixes},
  author = {Shields, Paul C.},
  year = {1992},
  pages = {403--409},
  file = {/Users/tobinsouth_imac/Zotero/storage/UTP2EJIJ/Shields - 1992 - Entropy and prefixes.pdf;/Users/tobinsouth_imac/Zotero/storage/8JMXUCX5/2244563.html},
  journal = {The Annals of Probability}
}

@article{shieldsUniversalRedundancyRates1993,
  title = {Universal Redundancy Rates Do Not Exist},
  author = {Shields, Paul C.},
  year = {1993},
  volume = {39},
  pages = {520--524},
  file = {/Users/tobinsouth_imac/Zotero/storage/3GYE2UP2/212281.html},
  journal = {IEEE transactions on information theory},
  number = {2}
}

@article{shieldsUniversalRedundancyRates1995,
  title = {Universal Redundancy Rates for the Class of {{B}}-Processes Do Not Exist},
  author = {Shields, Paul and Weiss, Benjamin},
  year = {1995},
  volume = {41},
  pages = {508--512},
  file = {/Users/tobinsouth_imac/Zotero/storage/R4CWNKAB/370156.html},
  journal = {IEEE transactions on information theory},
  number = {2}
}

@article{wynerAsymptoticPropertiesEntropy1989,
  title = {Some Asymptotic Properties of the Entropy of a Stationary Ergodic Data Source with Applications to Data Compression},
  author = {Wyner, A.D. and Ziv, J.},
  year = {Nov./1989},
  volume = {35},
  pages = {1250--1258},
  issn = {00189448},
  doi = {10.1109/18.45281},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {6}
}

@article{zivUniversalAlgorithmSequential1977,
  title = {A Universal Algorithm for Sequential Data Compression},
  author = {Ziv, J. and Lempel, A.},
  year = {1977},
  month = may,
  volume = {23},
  pages = {337--343},
  issn = {0018-9448},
  doi = {10.1109/TIT.1977.1055714},
  abstract = {A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.},
  file = {/Users/tobinsouth_imac/Zotero/storage/RUBCI5PU/Ziv and Lempel - 1977 - A universal algorithm for sequential data compress.pdf},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {3}
}


